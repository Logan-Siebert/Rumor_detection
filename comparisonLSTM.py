"""
File description : convergence analysis ----------------------------------------
                   For each input data folder, builds the mean accuracy (test)
                   array, then computes the associated std per epoch

"""



import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

fig, axs = plt.subplots(2, 1)

x1 = []

y001_val_acc = [0.631428599357605, 0.6585714221000671, 0.6642857193946838, 0.6742857098579407, 0.6671428680419922, 0.6928571462631226, 0.6742857098579407, 0.6885714530944824, 0.668571412563324, 0.6585714221000671, 0.677142858505249, 0.6800000071525574, 0.6785714030265808, 0.6514285802841187, 0.6742857098579407, 0.6885714530944824, 0.6885714530944824, 0.6471428275108337, 0.6785714030265808, 0.6785714030265808, 0.6714285612106323, 0.6857143044471741, 0.6742857098579407, 0.6814285516738892, 0.668571412563324, 0.6885714530944824, 0.6714285612106323, 0.6800000071525574, 0.6742857098579407, 0.6857143044471741, 0.6742857098579407, 0.6871428489685059, 0.6800000071525574, 0.691428542137146, 0.6871428489685059, 0.668571412563324, 0.6757143139839172, 0.6785714030265808, 0.6671428680419922, 0.6671428680419922, 0.6842857003211975, 0.6714285612106323, 0.6785714030265808, 0.6728571653366089, 0.6814285516738892, 0.6828571557998657, 0.677142858505249, 0.6871428489685059, 0.677142858505249, 0.6757143139839172, 0.6857143044471741, 0.6614285707473755, 0.6842857003211975, 0.6785714030265808, 0.6814285516738892, 0.6828571557998657, 0.6800000071525574, 0.6800000071525574, 0.6585714221000671, 0.6700000166893005, 0.6857143044471741, 0.6857143044471741, 0.6742857098579407, 0.677142858505249, 0.6785714030265808, 0.6942856907844543, 0.6800000071525574, 0.6557142734527588, 0.6842857003211975, 0.6814285516738892, 0.6814285516738892, 0.6814285516738892, 0.6842857003211975, 0.6857143044471741, 0.6871428489685059, 0.6814285516738892, 0.6828571557998657, 0.6842857003211975, 0.6714285612106323, 0.6714285612106323, 0.6785714030265808, 0.6471428275108337, 0.6757143139839172, 0.6785714030265808, 0.6857143044471741, 0.6800000071525574, 0.6814285516738892, 0.677142858505249, 0.6585714221000671, 0.6885714530944824, 0.6800000071525574, 0.6800000071525574, 0.6757143139839172, 0.6842857003211975, 0.6814285516738892, 0.6828571557998657, 0.6785714030265808, 0.6814285516738892, 0.691428542137146, 0.6842857003211975]

y001_train_acc = [0.5505514740943909, 0.6311274766921997, 0.6691176295280457, 0.6743260025978088, 0.6715686321258545, 0.6948529481887817, 0.671875, 0.6825980544090271, 0.6743260025978088, 0.688725471496582, 0.6789215803146362, 0.6920955777168274, 0.6930146813392639, 0.6997548937797546, 0.6902573704719543, 0.6914828419685364, 0.6979166865348816, 0.6801470518112183, 0.6936274766921997, 0.6908701062202454, 0.6914828419685364, 0.6896446347236633, 0.6960784196853638, 0.6960784196853638, 0.6945465803146362, 0.6908701062202454, 0.6960784196853638, 0.6942402124404907, 0.6914828419685364, 0.6859681606292725, 0.6945465803146362, 0.6902573704719543, 0.6979166865348816, 0.701899528503418, 0.6969975233078003, 0.6911764740943909, 0.703737735748291, 0.6780024766921997, 0.6988357901573181, 0.703125, 0.7009803652763367, 0.6982230544090271, 0.6985294222831726, 0.701286792755127, 0.6930146813392639, 0.6933210492134094, 0.6957720518112183, 0.6951593160629272, 0.6924019455909729, 0.6865808963775635, 0.6985294222831726, 0.7006739974021912, 0.7006739974021912, 0.6917892098426819, 0.7015931606292725, 0.6914828419685364, 0.6951593160629272, 0.6905637383460999, 0.7015931606292725, 0.6994485259056091, 0.701899528503418, 0.7003676295280457, 0.6991421580314636, 0.702512264251709, 0.7034313678741455, 0.701286792755127, 0.6890318393707275, 0.701899528503418, 0.7006739974021912, 0.6982230544090271, 0.7022058963775635, 0.702512264251709, 0.702512264251709, 0.6979166865348816, 0.7003676295280457, 0.6963847875595093, 0.6966911554336548, 0.6991421580314636, 0.6954656839370728, 0.7006739974021912, 0.6954656839370728, 0.7034313678741455, 0.6875, 0.6982230544090271, 0.7015931606292725, 0.7015931606292725, 0.6979166865348816, 0.6954656839370728, 0.7040441036224365, 0.7003676295280457, 0.7009803652763367, 0.6945465803146362, 0.7040441036224365, 0.7040441036224365, 0.7040441036224365, 0.7040441036224365, 0.688112735748291, 0.701899528503418, 0.6997548937797546, 0.7022058963775635]

y001_loss = [0.623161792755127, 0.6513480544090271, 0.6565563678741455, 0.6430760025978088, 0.6587010025978088, 0.6583946347236633, 0.6657475233078003, 0.656862735748291, 0.6488970518112183, 0.6672794222831726, 0.6672794222831726, 0.6620710492134094, 0.6697303652763367, 0.6743260025978088, 0.6746323704719543, 0.6764705777168274, 0.6795343160629272, 0.6746323704719543, 0.6694239974021912, 0.6798406839370728, 0.6853553652763367, 0.6780024766921997, 0.6804534196853638, 0.6816789507865906, 0.6822916865348816, 0.6850489974021912, 0.6865808963775635, 0.6752451062202454, 0.6920955777168274, 0.6761642098426819, 0.6896446347236633, 0.6908701062202454, 0.6838235259056091, 0.6801470518112183, 0.6783088445663452, 0.6936274766921997, 0.6807597875595093, 0.6945465803146362, 0.685661792755127, 0.6829044222831726, 0.6917892098426819, 0.6755514740943909, 0.6847426295280457, 0.6917892098426819, 0.6875, 0.6942402124404907, 0.6963847875595093, 0.688725471496582, 0.6920955777168274, 0.6896446347236633, 0.689338207244873, 0.6920955777168274, 0.6957720518112183, 0.6841298937797546, 0.6875, 0.686274528503418, 0.6884191036224365, 0.6908701062202454, 0.6911764740943909, 0.6924019455909729, 0.6859681606292725, 0.6908701062202454, 0.6924019455909729, 0.6942402124404907, 0.6936274766921997, 0.6957720518112183, 0.6933210492134094, 0.6890318393707275, 0.6963847875595093, 0.6920955777168274, 0.6776960492134094, 0.6920955777168274, 0.6789215803146362, 0.6908701062202454, 0.6942402124404907, 0.6936274766921997, 0.6963847875595093, 0.6951593160629272, 0.6844362616539001, 0.6902573704719543, 0.6709558963775635, 0.689338207244873, 0.6847426295280457, 0.6902573704719543, 0.6933210492134094, 0.6865808963775635, 0.6914828419685364, 0.6985294222831726, 0.6911764740943909, 0.6942402124404907, 0.6865808963775635, 0.6973039507865906, 0.6927083134651184, 0.6966911554336548, 0.6853553652763367, 0.6896446347236633, 0.6838235259056091, 0.6865808963775635, 0.6951593160629272, 0.6945465803146362]

for i in range(len(y001_val_acc)) :
    x1.append(i)


axs[0].grid(True)
axs[0].set_xlabel("Number of epochs")
axs[0].set_ylabel("Accuracy (%)")
axs[0].plot(x1, y001_val_acc, color = 'b', label='Val accuracy | lr = 0.001')
axs[0].plot(x1, y001_train_acc, color = 'r',  label='Train accuracy | lr = 0.001')
# axs[0].plot(x1, y001_loss, color = 'g', label = 'loss | lr = 0.001')
axs[0].legend()

plt.show()
